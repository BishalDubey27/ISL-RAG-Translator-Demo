=================================================================
REAL-TIME SIGN RECOGNITION OPTIMIZATION GUIDE
Minimum Latency & Maximum Performance
=================================================================

## CURRENT SYSTEM ANALYSIS

Your current system:
- Uses MediaPipe for feature extraction (pose, hands, face)
- LSTM model for classification
- Processes uploaded videos frame-by-frame
- Latency: ~2-3 seconds per video

## OPTIMIZATION STRATEGIES

### 1. FRAME PROCESSING OPTIMIZATION
   
   Current: Processes all frames
   Optimized: Process every 2nd or 3rd frame
   
   Benefit: 2-3x faster processing
   Trade-off: Slight accuracy reduction
   
   Implementation:
   - Skip frames: frame_skip = 2
   - Process only keyframes
   - Use motion detection to identify active signing

### 2. RESOLUTION REDUCTION
   
   Current: Full resolution (1920x1080 or higher)
   Optimized: 640x480 or 480x360
   
   Benefit: 4-9x faster MediaPipe processing
   Trade-off: Minimal accuracy loss
   
   Implementation:
   ```python
   frame = cv2.resize(frame, (640, 480))
   ```

### 3. MODEL OPTIMIZATION
   
   a) Use FP16 (Half Precision)
      - 2x faster on GPU
      - Minimal accuracy loss
      ```python
      model = model.half()
      ```
   
   b) Model Quantization
      - Convert to INT8
      - 4x faster, smaller model
      - Requires PyTorch quantization
   
   c) ONNX Runtime
      - Export model to ONNX
      - Use optimized runtime
      - 2-3x faster inference

### 4. BATCH PROCESSING
   
   Current: Process 1 frame at a time
   Optimized: Process 4-8 frames together
   
   Benefit: Better GPU utilization
   Implementation: Batch frames before inference

### 5. TEMPORAL SMOOTHING
   
   Use sliding window of predictions
   - Reduces jitter
   - Improves accuracy
   - Adds ~100ms latency but worth it
   
   Implementation:
   ```python
   prediction_buffer = deque(maxlen=5)
   # Take most common prediction
   ```

### 6. MEDIAPIPE OPTIMIZATION
   
   a) Reduce landmark complexity
      - Use only hands (skip face/pose if not needed)
      - 3x faster
   
   b) Lower MediaPipe model complexity
      - Use "lite" models instead of "full"
      - 2x faster
   
   c) Cache MediaPipe instances
      - Don't recreate for each frame
      - Reuse same instance

### 7. CLIENT-SIDE OPTIMIZATION
   
   a) Capture at lower FPS
      - 15 FPS instead of 30 FPS
      - Still smooth for sign language
   
   b) Compress frames before sending
      - JPEG compression (quality=70)
      - Reduces network latency
   
   c) Use WebRTC for streaming
      - Lower latency than HTTP
      - Better for real-time

### 8. SERVER-SIDE OPTIMIZATION
   
   a) Use async processing
      - Don't block on inference
      - Queue-based processing
   
   b) GPU acceleration
      - CUDA for PyTorch
      - Ensure GPU is being used
   
   c) Multi-threading
      - Separate thread for MediaPipe
      - Separate thread for model inference

## RECOMMENDED ARCHITECTURE

### Option 1: HTTP Polling (Simplest)
```
Client (Browser)
  ↓ Capture frame every 200ms
  ↓ Send JPEG to server
Server
  ↓ Extract features (MediaPipe)
  ↓ Run inference (LSTM)
  ↓ Return prediction
Client
  ↓ Display result
  ↓ Repeat
```

Latency: 300-500ms
Pros: Simple, works everywhere
Cons: Higher latency, more bandwidth

### Option 2: WebSocket (Better)
```
Client ←→ WebSocket ←→ Server
  Continuous bidirectional stream
  Lower latency, efficient
```

Latency: 150-300ms
Pros: Real-time, efficient
Cons: Requires WebSocket support

### Option 3: WebRTC (Best)
```
Client ←→ WebRTC ←→ Server
  Peer-to-peer video stream
  Lowest latency
```

Latency: 50-150ms
Pros: Lowest latency, best quality
Cons: Complex setup

## IMPLEMENTATION STEPS

### STEP 1: Optimize MediaPipe (Quick Win)

File: sign_recognition/models/mediapipe_extractor.py

Add these optimizations:

```python
class MediaPipeExtractor:
    def __init__(self, use_lite=True, hands_only=False):
        self.use_lite = use_lite
        self.hands_only = hands_only
        
        if hands_only:
            # Only use hands for faster processing
            self.hand_landmarker = hand_landmarker.HandLandmarker.create_from_model_path(hand_path)
            self.total_dim = 63 * 2  # Just hands
        else:
            # Full body
            # ... existing code
    
    def extract_frame(self, frame):
        # Resize frame for faster processing
        frame = cv2.resize(frame, (640, 480))
        
        # ... rest of extraction
```

### STEP 2: Add Frame Skipping

```python
class RealtimeRecognizer:
    def __init__(self, frame_skip=2):
        self.frame_skip = frame_skip
        self.frame_count = 0
    
    def should_process_frame(self):
        self.frame_count += 1
        return self.frame_count % self.frame_skip == 0
```

### STEP 3: Optimize Model Inference

```python
# Use FP16 on GPU
if torch.cuda.is_available():
    model = model.half()
    model = model.cuda()

# Use torch.no_grad() for inference
with torch.no_grad():
    output = model(input)
```

### STEP 4: Add Prediction Smoothing

```python
from collections import deque, Counter

class SmoothedPredictor:
    def __init__(self, buffer_size=5):
        self.buffer = deque(maxlen=buffer_size)
    
    def add_prediction(self, label, confidence):
        self.buffer.append((label, confidence))
    
    def get_smoothed_prediction(self):
        if len(self.buffer) < 3:
            return self.buffer[-1] if self.buffer else None
        
        # Most common label
        labels = [p[0] for p in self.buffer]
        most_common = Counter(labels).most_common(1)[0][0]
        
        # Average confidence for that label
        confidences = [c for l, c in self.buffer if l == most_common]
        avg_confidence = sum(confidences) / len(confidences)
        
        return (most_common, avg_confidence)
```

### STEP 5: Client-Side Optimization

In your HTML/JavaScript:

```javascript
// Capture at lower FPS
const FPS = 15;  // Instead of 30
const FRAME_INTERVAL = 1000 / FPS;

// Resize canvas before sending
canvas.width = 640;
canvas.height = 480;

// Compress JPEG
const blob = await new Promise(resolve => 
    canvas.toBlob(resolve, 'image/jpeg', 0.7)
);

// Send every Nth frame
if (frameCount % 2 === 0) {
    sendFrameToServer(blob);
}
```

## PERFORMANCE TARGETS

### Minimum (Acceptable)
- Latency: < 500ms
- FPS: > 10
- Accuracy: > 70%

### Good
- Latency: < 300ms
- FPS: > 15
- Accuracy: > 80%

### Excellent
- Latency: < 150ms
- FPS: > 20
- Accuracy: > 85%

## TESTING & BENCHMARKING

### Measure Latency

```python
import time

start = time.time()
# ... processing
end = time.time()
latency_ms = (end - start) * 1000
print(f"Latency: {latency_ms:.2f}ms")
```

### Measure FPS

```python
frame_count = 0
start_time = time.time()

while True:
    # Process frame
    frame_count += 1
    
    if frame_count % 30 == 0:
        elapsed = time.time() - start_time
        fps = frame_count / elapsed
        print(f"FPS: {fps:.2f}")
```

### Profile Code

```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# Your code here

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)  # Top 20 slowest functions
```

## QUICK WINS (Implement First)

1. ✅ Resize frames to 640x480
2. ✅ Skip every other frame
3. ✅ Use FP16 on GPU
4. ✅ Add prediction smoothing
5. ✅ Cache MediaPipe models
6. ✅ Reduce client FPS to 15
7. ✅ JPEG compression (quality=70)
8. ✅ Use torch.no_grad()

These 8 changes can reduce latency by 50-70%!

## ADVANCED OPTIMIZATIONS (Later)

1. Model quantization (INT8)
2. ONNX Runtime
3. TensorRT (NVIDIA GPUs)
4. WebSocket streaming
5. WebRTC peer-to-peer
6. Edge TPU (Google Coral)
7. Model pruning
8. Knowledge distillation

## HARDWARE RECOMMENDATIONS

### Minimum
- CPU: 4 cores, 2.5GHz+
- RAM: 8GB
- GPU: Not required but helps

### Recommended
- CPU: 8 cores, 3.0GHz+
- RAM: 16GB
- GPU: NVIDIA GTX 1060 or better
- CUDA: 11.0+

### Optimal
- CPU: 12+ cores, 3.5GHz+
- RAM: 32GB
- GPU: NVIDIA RTX 3060 or better
- CUDA: 11.8+

## TROUBLESHOOTING

### High Latency (>500ms)
- Check if GPU is being used
- Reduce frame resolution
- Skip more frames
- Use FP16

### Low FPS (<10)
- Reduce MediaPipe complexity
- Use hands-only mode
- Increase frame skip
- Check CPU usage

### Poor Accuracy (<70%)
- Don't skip too many frames
- Use prediction smoothing
- Ensure good lighting
- Check camera quality

### High CPU Usage
- Use GPU if available
- Reduce frame rate
- Optimize MediaPipe
- Use async processing

## NEXT STEPS

1. Implement quick wins (above)
2. Measure baseline performance
3. Apply optimizations one by one
4. Measure improvement after each
5. Find optimal balance of speed/accuracy

Target: <200ms latency, >15 FPS, >80% accuracy

=================================================================
